{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh6Y-HgrpbAx",
        "outputId": "6e4f8ac0-b276-4970-eeeb-f6b3c3e3c699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install requests beautifulsoup4 pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from urllib.parse import urljoin\n",
        "import re\n"
      ],
      "metadata": {
        "id": "OLZhh1ncqBhi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_URL = \"https://books.toscrape.com/\"\n",
        "\n",
        "def get_soup(url):\n",
        "    resp = requests.get(url)\n",
        "    resp.raise_for_status()\n",
        "    return BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "RATING_MAP = {\n",
        "    \"One\": 1,\n",
        "    \"Two\": 2,\n",
        "    \"Three\": 3,\n",
        "    \"Four\": 4,\n",
        "    \"Five\": 5\n",
        "}\n",
        "\n",
        "def get_soup(url: str) -> BeautifulSoup:\n",
        "    resp = requests.get(url)\n",
        "    resp.encoding = \"utf-8\"        # penting: hilangkan karakter 'Â'\n",
        "    resp.raise_for_status()\n",
        "    return BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "def clean_price(text: str):\n",
        "    if text:\n",
        "        return text.replace(\"Â\", \"\").strip()\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "VhdFU6HEqF76"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_book_detail(book_url: str, list_page_rating: int, list_page_title: str) -> dict:\n",
        "    soup = get_soup(book_url)\n",
        "\n",
        "    breadcrumb_links = soup.select(\"ul.breadcrumb li a\")\n",
        "    if len(breadcrumb_links) >= 3:\n",
        "        # index 2 biasanya kategori (Home=0, Books=1, Category=2)\n",
        "        category = breadcrumb_links[2].get_text(strip=True)\n",
        "    elif len(breadcrumb_links) >= 2:\n",
        "        category = breadcrumb_links[-1].get_text(strip=True)\n",
        "    else:\n",
        "        category = None\n",
        "\n",
        "    # ---------- table info ----------\n",
        "    table_rows = soup.select(\"table.table.table-striped tr\")\n",
        "    table_data = {}\n",
        "    for row in table_rows:\n",
        "        th = row.find(\"th\").get_text(strip=True)\n",
        "        td = row.find(\"td\").get_text(strip=True)\n",
        "        table_data[th] = td\n",
        "\n",
        "    code = table_data.get(\"UPC\")\n",
        "    price_excl_tax = clean_price(table_data.get(\"Price (excl. tax)\"))\n",
        "    price_incl_tax = clean_price(table_data.get(\"Price (incl. tax)\"))\n",
        "    tax = clean_price(table_data.get(\"Tax\"))\n",
        "    availability = table_data.get(\"Availability\")\n",
        "    num_reviews = table_data.get(\"Number of reviews\")\n",
        "\n",
        "    # ---------- stock status & number of stock ----------\n",
        "    stock_status = availability\n",
        "    num_stock = None\n",
        "    if availability:\n",
        "        match = re.search(r\"\\((\\d+)\\s+available\\)\", availability)\n",
        "        if match:\n",
        "            num_stock = int(match.group(1))\n",
        "\n",
        "    # ---------- description ----------\n",
        "    desc = None\n",
        "    desc_div = soup.find(\"div\", id=\"product_description\")\n",
        "    if desc_div:\n",
        "        p = desc_div.find_next_sibling(\"p\")\n",
        "        if p:\n",
        "            desc = p.get_text(strip=True)\n",
        "\n",
        "    # ---------- cover image ----------\n",
        "    img_tag = soup.select_one(\"div.item.active img\")\n",
        "    cover_url = None\n",
        "    if img_tag and img_tag.get(\"src\"):\n",
        "        cover_url = urljoin(book_url, img_tag[\"src\"])\n",
        "\n",
        "    # ---------- rating & title ----------\n",
        "    rating = list_page_rating\n",
        "    title = list_page_title\n",
        "\n",
        "    # ---------- number of reviews -> int ----------\n",
        "    num_reviews_int = None\n",
        "    if num_reviews is not None:\n",
        "        try:\n",
        "            num_reviews_int = int(num_reviews)\n",
        "        except ValueError:\n",
        "            num_reviews_int = None\n",
        "\n",
        "    return {\n",
        "        \"category\": category,\n",
        "        \"code\": code,\n",
        "        \"cover\": cover_url,\n",
        "        \"title\": title,\n",
        "        \"rating\": rating,\n",
        "        \"price (excl. tax)\": price_excl_tax,\n",
        "        \"price (incl. tax)\": price_incl_tax,\n",
        "        \"tax\": tax,\n",
        "        \"stock status\": stock_status,\n",
        "        \"number of stock available\": num_stock,\n",
        "        \"description\": desc,\n",
        "        \"number of reviews\": num_reviews_int\n",
        "    }"
      ],
      "metadata": {
        "id": "NqnA4KhPqJRk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_data = []\n",
        "\n",
        "current_url = BASE_URL\n",
        "\n",
        "while True:\n",
        "    print(\"Scraping list page:\", current_url)\n",
        "    soup = get_soup(current_url)\n",
        "\n",
        "    # setiap buku di list page\n",
        "    for article in soup.select(\"article.product_pod\"):\n",
        "        # title & url detail\n",
        "        a_tag = article.select_one(\"h3 a\")\n",
        "        rel_link = a_tag.get(\"href\")\n",
        "        book_title = a_tag.get(\"title\").strip()\n",
        "        book_url = urljoin(current_url, rel_link)\n",
        "\n",
        "        # rating dari list page\n",
        "        rating_class = article.select_one(\"p.star-rating\")[\"class\"]\n",
        "        # contoh: ['star-rating', 'Three']\n",
        "        rating_word = None\n",
        "        for c in rating_class:\n",
        "            if c in RATING_MAP:\n",
        "                rating_word = c\n",
        "                break\n",
        "        rating_value = RATING_MAP.get(rating_word, None)\n",
        "\n",
        "        # parse detail book\n",
        "        book_info = parse_book_detail(book_url, rating_value, book_title)\n",
        "        books_data.append(book_info)\n",
        "\n",
        "        # kalau sudah 1000 buku, berhenti\n",
        "        if len(books_data) >= 1000:\n",
        "            break\n",
        "\n",
        "    if len(books_data) >= 1000:\n",
        "        break\n",
        "\n",
        "    # cari link next page\n",
        "    next_link = soup.select_one(\"li.next a\")\n",
        "    if next_link:\n",
        "        next_url = urljoin(current_url, next_link.get(\"href\"))\n",
        "        current_url = next_url\n",
        "    else:\n",
        "        break\n",
        "\n",
        "print(\"Total buku yang di-scrape:\", len(books_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUlD7h8_qNnN",
        "outputId": "323b9ac3-467d-4c2d-f8ff-cadd863b5927"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping list page: https://books.toscrape.com/\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-2.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-3.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-4.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-5.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-6.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-7.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-8.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-9.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-10.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-11.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-12.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-13.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-14.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-15.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-16.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-17.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-18.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-19.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-20.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-21.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-22.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-23.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-24.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-25.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-26.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-27.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-28.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-29.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-30.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-31.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-32.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-33.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-34.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-35.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-36.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-37.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-38.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-39.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-40.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-41.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-42.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-43.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-44.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-45.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-46.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-47.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-48.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-49.html\n",
            "Scraping list page: https://books.toscrape.com/catalogue/page-50.html\n",
            "Total buku yang di-scrape: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(books_data)\n",
        "\n",
        "# optional: cek kolom & 5 baris pertama\n",
        "print(df.shape)   # harusnya (1000, 12)\n",
        "print(df.head())\n",
        "\n",
        "# simpan ke CSV jika perlu\n",
        "# CSV\n",
        "df.to_csv(\"books_toscrape_1000.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# Excel\n",
        "df.to_excel(\"books_toscrape_1000.xlsx\", index=False, sheet_name=\"Books Data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C913pRpPqc6y",
        "outputId": "6e11b3ee-8fb4-4d11-fe2f-332f6e8572f3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 12)\n",
            "             category              code  \\\n",
            "0              Poetry  a897fe39b1053632   \n",
            "1  Historical Fiction  90fa61229261140a   \n",
            "2             Fiction  6957f44c3847a760   \n",
            "3             Mystery  e00eb4fd7b871a48   \n",
            "4             History  4165285e1663650f   \n",
            "\n",
            "                                               cover  \\\n",
            "0  https://books.toscrape.com/media/cache/fe/72/f...   \n",
            "1  https://books.toscrape.com/media/cache/08/e9/0...   \n",
            "2  https://books.toscrape.com/media/cache/ee/cf/e...   \n",
            "3  https://books.toscrape.com/media/cache/c0/59/c...   \n",
            "4  https://books.toscrape.com/media/cache/ce/5f/c...   \n",
            "\n",
            "                                   title  rating price (excl. tax)  \\\n",
            "0                   A Light in the Attic       3            £51.77   \n",
            "1                     Tipping the Velvet       1            £53.74   \n",
            "2                             Soumission       1            £50.10   \n",
            "3                          Sharp Objects       4            £47.82   \n",
            "4  Sapiens: A Brief History of Humankind       5            £54.23   \n",
            "\n",
            "  price (incl. tax)    tax             stock status  \\\n",
            "0            £51.77  £0.00  In stock (22 available)   \n",
            "1            £53.74  £0.00  In stock (20 available)   \n",
            "2            £50.10  £0.00  In stock (20 available)   \n",
            "3            £47.82  £0.00  In stock (20 available)   \n",
            "4            £54.23  £0.00  In stock (20 available)   \n",
            "\n",
            "   number of stock available  \\\n",
            "0                         22   \n",
            "1                         20   \n",
            "2                         20   \n",
            "3                         20   \n",
            "4                         20   \n",
            "\n",
            "                                         description  number of reviews  \n",
            "0  It's hard to imagine a world without A Light i...                  0  \n",
            "1  \"Erotic and absorbing...Written with starling ...                  0  \n",
            "2  Dans une France assez proche de la nôtre, un h...                  0  \n",
            "3  WICKED above her hipbone, GIRL across her hear...                  0  \n",
            "4  From a renowned historian comes a groundbreaki...                  0  \n"
          ]
        }
      ]
    }
  ]
}